{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ee564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Demo for use yolo v3\n",
    "\"\"\"\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from model.yolo_model import YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169f02b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afe45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    \"\"\"Resize, reduce and expand image.\n",
    "\n",
    "    # Argument:\n",
    "        img: original image.\n",
    "\n",
    "    # Returns\n",
    "        image: ndarray(64, 64, 3), processed image.\n",
    "    \"\"\"\n",
    "    image = cv2.resize(img, (416, 416),\n",
    "                       interpolation=cv2.INTER_CUBIC)\n",
    "    image = np.array(image, dtype='float32')\n",
    "    image /= 255.\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03ea514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9->traffic light\n",
    "\n",
    "def get_classes(file):\n",
    "    \"\"\"Get classes name.\n",
    "\n",
    "    # Argument:\n",
    "        file: classes name for database.\n",
    "\n",
    "    # Returns\n",
    "        class_names: List, classes name.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(file) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "350e733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_image =[]\n",
    "def draw(image, boxes, scores, classes, all_classes):\n",
    "    \"\"\"Draw the boxes on the image.\n",
    "\n",
    "    # Argument:\n",
    "        image: original image.\n",
    "        boxes: ndarray, boxes of objects.\n",
    "        classes: ndarray, classes of objects.\n",
    "        scores: ndarray, scores of objects.\n",
    "        all_classes: all classes name.\n",
    "    \"\"\"\n",
    "    for box, score, cl in zip(boxes, scores, classes):\n",
    "        x, y, w, h = box\n",
    "\n",
    "        top = max(0, np.floor(x + 0.5).astype(int))\n",
    "        left = max(0, np.floor(y + 0.5).astype(int))\n",
    "        right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))\n",
    "        bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))\n",
    "        \n",
    "        print(f\"cl :{cl}\")\n",
    "        if cl == 9:\n",
    "            cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n",
    "            cv2.putText(image, '{0} {1:.2f}'.format(all_classes[cl], score),\n",
    "                        (top, left - 6),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.6, (0, 0, 255), 1,\n",
    "                        cv2.LINE_AA)\n",
    "            \n",
    "                    \n",
    "                            \n",
    "#             for (root, dirs, files) in os.walk('images/test'):\n",
    "#             if files:\n",
    "#                 for f in files:\n",
    "#                     print(f)\n",
    "#                     path = os.path.join(root, f)\n",
    "#                     image = cv2.imread(path)\n",
    "#                     image = detect_image(image, yolo, all_classes)\n",
    "#                     cv2.imwrite('images/res/' + f, image)\n",
    "            crop_area = image[left:bottom,top:right]\n",
    "            cv2.imwrite('images/crop_area/' + f, crop_area)\n",
    "#             cv2.imwrite('C:/Users/Admin/PycharmProjects/pythonProject/YOLOv3-master/left:bottom/images/crop_area/',crop_area)\n",
    "            \n",
    "#         cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n",
    "#         cv2.putText(image, '{0} {1:.2f}'.format(all_classes[cl], score),\n",
    "#                     (top, left - 6),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                     0.6, (0, 0, 255), 1,\n",
    "#                     cv2.LINE_AA)\n",
    "\n",
    "        print('class: {0}, score: {1:.2f}'.format(all_classes[cl], score))\n",
    "        print('box coordinate x,y,w,h: {0}'.format(box))\n",
    "\n",
    "    print()\n",
    "    return list_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3403c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(image, yolo, all_classes):\n",
    "    \"\"\"Use yolo v3 to detect images.\n",
    "\n",
    "    # Argument:\n",
    "        image: original image.\n",
    "        yolo: YOLO, yolo model.\n",
    "        all_classes: all classes name.\n",
    "\n",
    "    # Returns:\n",
    "        image: processed image.\n",
    "    \"\"\"\n",
    "    pimage = process_image(image)\n",
    "\n",
    "    start = time.time()\n",
    "    boxes, classes, scores = yolo.predict(pimage, image.shape)\n",
    "    end = time.time()\n",
    "\n",
    "    print('time: {0:.2f}s'.format(end - start))\n",
    "\n",
    "    if boxes is not None:\n",
    "        draw(image, boxes, scores, classes, all_classes)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7edbdcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_video(video, yolo, all_classes):\n",
    "    \"\"\"Use yolo v3 to detect video.\n",
    "\n",
    "    # Argument:\n",
    "        video: video file.\n",
    "        yolo: YOLO, yolo model.\n",
    "        all_classes: all classes name.\n",
    "    \"\"\"\n",
    "    video_path = os.path.join(\"videos\", \"test\", video)\n",
    "    camera = cv2.VideoCapture(video_path)\n",
    "    cv2.namedWindow(\"detection\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    # Prepare for saving the detected video\n",
    "    sz = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mpeg')\n",
    "\n",
    "    vout = cv2.VideoWriter()\n",
    "    vout.open(os.path.join(\"videos\", \"res\", video), fourcc, 20, sz, True)\n",
    "\n",
    "    while True:\n",
    "        res, frame = camera.read()\n",
    "\n",
    "        if not res:\n",
    "            break\n",
    "\n",
    "        image = detect_image(frame, yolo, all_classes)\n",
    "        cv2.imshow(\"detection\", image)\n",
    "\n",
    "        # Save the video frame by frame\n",
    "        vout.write(image)\n",
    "\n",
    "        if cv2.waitKey(110) & 0xff == 27:\n",
    "                break\n",
    "\n",
    "    vout.release()\n",
    "    camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd470e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# if __name__ == '__main__':\n",
    "#     yolo = YOLO(0.6, 0.5)\n",
    "#     file = 'data/coco_classes.txt'\n",
    "#     all_classes = get_classes(file)\n",
    "\n",
    "\n",
    "yolo = YOLO(0.6, 0.5)\n",
    "file = 'data/coco_classes.txt'\n",
    "all_classes = get_classes(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a5e4dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog.jpg\n",
      "time: 10.18s\n",
      "cl :16\n",
      "class: dog, score: 1.00\n",
      "box coordinate x,y,w,h: [124.10609436 220.43732643 195.35037231 321.95930804]\n",
      "cl :1\n",
      "class: bicycle, score: 1.00\n",
      "box coordinate x,y,w,h: [119.10217667 118.63843918 448.7917099  321.94878453]\n",
      "cl :7\n",
      "class: truck, score: 0.91\n",
      "box coordinate x,y,w,h: [468.68074036  84.48197079 227.29340744  83.52550397]\n",
      "\n",
      "eagle.jpg\n",
      "time: 2.16s\n",
      "cl :14\n",
      "class: bird, score: 0.96\n",
      "box coordinate x,y,w,h: [116.68165441 102.96123505 512.00514671 353.67519188]\n",
      "\n",
      "giraffe.jpg\n",
      "time: 2.33s\n",
      "cl :22\n",
      "class: zebra, score: 0.97\n",
      "box coordinate x,y,w,h: [271.4728713  197.00688124 157.91193768 260.55246592]\n",
      "cl :23\n",
      "class: giraffe, score: 1.00\n",
      "box coordinate x,y,w,h: [156.34179115  38.96565735 288.86812316 359.70112567]\n",
      "\n",
      "horses.jpg\n",
      "time: 2.09s\n",
      "cl :17\n",
      "class: horse, score: 0.99\n",
      "box coordinate x,y,w,h: [439.62667483 217.98129272 160.1829722  125.79316653]\n",
      "cl :17\n",
      "class: horse, score: 0.97\n",
      "box coordinate x,y,w,h: [  6.19349234 193.56124878 301.11572295 222.87346414]\n",
      "cl :17\n",
      "class: horse, score: 0.96\n",
      "box coordinate x,y,w,h: [243.41676384 179.07377625 203.38804318 172.56821119]\n",
      "cl :17\n",
      "class: horse, score: 0.62\n",
      "box coordinate x,y,w,h: [ -3.25958854 199.81671143 171.15247692 173.09807704]\n",
      "\n",
      "person.jpg\n",
      "time: 2.55s\n",
      "cl :0\n",
      "class: person, score: 1.00\n",
      "box coordinate x,y,w,h: [187.65592575  82.93733287  91.79075424 306.85243028]\n",
      "cl :17\n",
      "class: horse, score: 1.00\n",
      "box coordinate x,y,w,h: [396.35890961 137.40118432 215.85382462 208.32020985]\n",
      "cl :16\n",
      "class: dog, score: 1.00\n",
      "box coordinate x,y,w,h: [ 61.19190216 263.38934135 145.3668642   88.43165885]\n",
      "\n",
      "t1.jpg\n",
      "time: 2.80s\n",
      "cl :9\n",
      "class: traffic light, score: 1.00\n",
      "box coordinate x,y,w,h: [118.63767475  23.78337979 185.92112795 374.70880079]\n",
      "cl :9\n",
      "class: traffic light, score: 0.76\n",
      "box coordinate x,y,w,h: [420.76882267 142.55504751  73.44887322 113.8915897 ]\n",
      "\n",
      "t2.jpg\n",
      "time: 2.63s\n",
      "cl :9\n",
      "class: traffic light, score: 0.98\n",
      "box coordinate x,y,w,h: [175.20989227  40.70384018  54.58356714 120.3732653 ]\n",
      "\n",
      "t3.jpg\n",
      "time: 2.49s\n",
      "takagaki.jpg\n",
      "time: 2.23s\n",
      "cl :0\n",
      "class: person, score: 1.00\n",
      "box coordinate x,y,w,h: [  51.79349899  175.08844376  891.41739249 1116.60473237]\n",
      "\n",
      "tl.jpg\n",
      "time: 2.33s\n",
      "cl :2\n",
      "class: car, score: 0.62\n",
      "box coordinate x,y,w,h: [ 11.08126827 147.10166788 152.80507344  20.43388604]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # detect images in test floder.\n",
    "    for (root, dirs, files) in os.walk('images/test'):\n",
    "        if files:\n",
    "            for f in files:\n",
    "                print(f)\n",
    "                path = os.path.join(root, f)\n",
    "                image = cv2.imread(path)\n",
    "                image = detect_image(image, yolo, all_classes)\n",
    "                cv2.imwrite('images/res/' + f, image)\n",
    "\n",
    "    # detect videos one at a time in videos/test folder    \n",
    "#     video = 'library1.mp4'\n",
    "#     detect_video(video, yolo, all_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e4964",
   "metadata": {},
   "source": [
    "<h1>Color detection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea2a499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
